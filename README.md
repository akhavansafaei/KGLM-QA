# KGLM-QA: Knowledge Graph-Enhanced Large Language Models for Question Answering

This repository contains the implementation and datasets for the paper **"KGLM-QA: A Novel Approach for Knowledge Graph-Enhanced Large Language Models for Question Answering"**, presented at the 2024 15th International Conference on Information and Knowledge Technology (IKT).

## Project Description

KGLM-QA is a framework that enhances large language models (LLMs) for question answering by incorporating structured knowledge from knowledge graphs (KGs). The system leverages entity extraction, semantic similarity scoring, and adaptive exploration of knowledge graphs to improve accuracy, particularly for knowledge-intensive queries involving long-tail entities or specific factual information.

Key features include:
- Iterative subgraph exploration and SPARQL-based query generation.
- Retrieval-Augmented Generation (RAG) for integrating KG knowledge with LLM responses.
- Modular design for easy adaptation to different domains and tasks.

## Code

The repository includes all the code required to replicate the experiments and results described in the paper. **Please note that API keys for the Gemini 1.5 Flash model are not included**. You must obtain your API keys from Gemini to use this project.

### Examples
The repository provides:
- Examples of questions along with their corresponding knowledge graphs.
- Workflows demonstrating SPARQL query generation and RAG integration.

## Datasets

This project utilizes two datasets for evaluation:
1. **test_with_rag_gemini_answer.csv**: A set of 1,000 questions where the answers were generated using the RAG approach.
2. **test_with_llm_gemini_answer.csv**: A set of 1,000 questions of four types (What, Which, Where, Who), with answers directly generated by the LLM.

Additionally:
- **P131.test.json**: The original dataset containing "Where" questions from the Entity Questions dataset.
- **Custom Dataset**: A dataset created by random sampling across all 24 test datasets in the Entity Questions dataset.

These datasets highlight the improved accuracy and reliability of the KGLM-QA system across diverse question types.

## Reproducing Results

To reproduce the experiments:
1. Clone the repository.
2. Install the required dependencies listed in `requirements.txt`.
3. Obtain and set up your API keys for Gemini.
4. Use the provided scripts to run the system on the included datasets or your custom data.

## Results Overview

The proposed KGLM-QA system achieved significant improvements over baseline LLM performance:
- **Partially Correct Answers**: Accuracy increased from 36% (LLM only) to 71% (RAG approach).
- **Exactly Correct Answers**: Accuracy improved from 22% (LLM only) to 69% (RAG approach).

## Citation

If you use this repository in your research, please cite:

@inproceedings{akhavansafaei2024kglmqa, title={KGLM-QA: A Novel Approach for Knowledge Graph-Enhanced Large Language Models for Question Answering}, author={Alireza Akhavan Safaei, Reza Ramezani, Pegah Saboori, Mohammadali Nematbakhsh}, booktitle={2024 15th International Conference on Information and Knowledge Technology (IKT)}, year={2024}, organization={IEEE} }


## Contact

For any inquiries or issues, please contact:
- **Email**: alirezaakhavansafaei@gmail.com
- **Website**: [studylab.ir](http://studylab.ir)
